from idaes.core.surrogate.metrics import compute_fit_metrics
from idaes.core.surrogate.pysmo_surrogate import (
    PysmoPolyTrainer,
    PysmoSurrogate,
    PysmoKrigingTrainer,
    PysmoRBFTrainer,
)
from idaes.core.surrogate.sampling.data_utils import split_training_validation
from idaes.core.surrogate.plotting.sm_plotter import (
    surrogate_scatter2D,
    surrogate_scatter3D,
    surrogate_parity,
    surrogate_residual,
)

from pyomo.environ import value

import pandas as pd

# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_polyregression.html
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/index.html#pysmo-python-based-surrogate-modeling-objects
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/plotting/index.html#visualizing-surrogate-model-results
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_radialbasisfunctions.html


def main():
    # data is generated by running generate_diffusion_data.py
    data_dict = {
        "D_11_scaled": "surrogate_data/kriging_or_rbf/D_11_scaled.csv",
        # "D_12_scaled": "surrogate_data/kriging_or_rbf/D_12_scaled.csv",
        # "D_21_scaled": "surrogate_data/kriging_or_rbf/D_21_scaled.csv",
        # "D_22_scaled": "surrogate_data/kriging_or_rbf/D_22_scaled.csv",
        # "alpha_1": "surrogate_data/kriging_or_rbf/alpha_1.csv",
        # "alpha_2": "surrogate_data/kriging_or_rbf/alpha_2.csv",
    }
    data_dict_large = {
        "D_11_scaled": "surrogate_data/D_11_scaled.csv",
        "D_12_scaled": "surrogate_data/D_12_scaled.csv",
        "D_21_scaled": "surrogate_data/D_21_scaled.csv",
        "D_22_scaled": "surrogate_data/D_22_scaled.csv",
        "alpha_1": "surrogate_data/alpha_1.csv",
        "alpha_2": "surrogate_data/alpha_2.csv",
    }

    for var, datafile in data_dict.items():
        train_data_set(train_rbf_surrogate_model, datafile, var)
        # train_data_set(train_kriging_surrogate_model, datafile, var)

    polynomial = False
    if polynomial:
        for var, datafile in data_dict_large.items():
            train_data_set(train_polynomial_surrogate_model, datafile, var)


def train_data_set(
    surrogate_model_training_function,
    datafilename,
    paramtername,
    save=False,
    savefile=None,
):
    trained_model = surrogate_model_training_function(
        datafile=datafilename,
        parametername=paramtername,
    )
    if save:
        trained_model.save_to_file(
            savefile,
            overwrite=True,
        )


def train_polynomial_surrogate_model(datafile, parametername, max_order=4):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    # create PySMO regression trainer object
    pr_trainer = PysmoPolyTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    # set PySMO options
    pr_trainer.config.maximum_polynomial_order = max_order

    # train surrogate model
    poly_train = pr_trainer.train_surrogate()

    surrogate = PysmoSurrogate(poly_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_kriging_surrogate_model(datafile, parametername):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    krg_trainer = PysmoKrigingTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    krg_trainer.config.numerical_gradients = False

    krg_train = krg_trainer.train_surrogate()

    surrogate = PysmoSurrogate(krg_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_rbf_surrogate_model(datafile, parametername):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)
    print(data_training)

    rbf_trainer = PysmoRBFTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    rbf_trainer.config.basis_function = "cubic"

    rbf_train = rbf_trainer.train_surrogate()

    surrogate = PysmoSurrogate(rbf_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


if __name__ == "__main__":
    main()
