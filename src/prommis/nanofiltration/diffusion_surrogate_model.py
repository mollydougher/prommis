from idaes.core.surrogate.metrics import compute_fit_metrics
from idaes.core.surrogate.pysmo_surrogate import (
    PysmoPolyTrainer,
    PysmoSurrogate,
    PysmoKrigingTrainer,
    PysmoRBFTrainer,
)
from idaes.core.surrogate.sampling.data_utils import split_training_validation
from idaes.core.surrogate.plotting.sm_plotter import (
    surrogate_scatter2D,
    surrogate_scatter3D,
    surrogate_parity,
    surrogate_residual,
)

from pyomo.environ import value

import pandas as pd

# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_polyregression.html
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/index.html#pysmo-python-based-surrogate-modeling-objects
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/plotting/index.html#visualizing-surrogate-model-results
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_radialbasisfunctions.html


def main():
    # data is generated by running generate_diffusion_data.py
    data_dict_two_salt = {
        "D_11_scaled": "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/D_11_scaled.csv",
        "D_12_scaled": "surrogate_data/kriging_or_rbf/D_12_scaled.csv",
        "D_21_scaled": "surrogate_data/kriging_or_rbf/D_21_scaled.csv",
        "D_22_scaled": "surrogate_data/kriging_or_rbf/D_22_scaled.csv",
        "alpha_1": "surrogate_data/kriging_or_rbf/alpha_1.csv",
        "alpha_2": "surrogate_data/kriging_or_rbf/alpha_2.csv",
    }
    data_dict_large_two_salt = {
        "D_11_scaled": "surrogate_data/D_11_scaled.csv",
        "D_12_scaled": "surrogate_data/D_12_scaled.csv",
        "D_21_scaled": "surrogate_data/D_21_scaled.csv",
        "D_22_scaled": "surrogate_data/D_22_scaled.csv",
        "alpha_1": "surrogate_data/alpha_1.csv",
        "alpha_2": "surrogate_data/alpha_2.csv",
    }

    # for var, datafile in data_dict_two_salt.items():
    #     train_data_set(train_rbf_surrogate_model, datafile, var, True, "surrogate_models/rbf_pysmo_surrogate_d11_scaled")
    #     # train_data_set(train_kriging_surrogate_model, datafile, var)

    # polynomial = False
    # if polynomial:
    #     for var, datafile in data_dict_large_two_salt.items():
    #         train_data_set(train_polynomial_surrogate_model, datafile, var)

    # data is generated by running generate_diffusion_data.py
    data_dict_three_salt = {
        "D_11_scaled": [
            "d11",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_11_scaled.csv",
        ],
        "D_12_scaled": [
            "d12",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_12_scaled.csv",
        ],
        "D_13_scaled": [
            "d13",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_13_scaled.csv",
        ],
        "D_21_scaled": [
            "d21",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_21_scaled.csv",
        ],
        "D_22_scaled": [
            "d22",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_22_scaled.csv",
        ],
        "D_23_scaled": [
            "d23",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_23_scaled.csv",
        ],
        "D_31_scaled": [
            "d31",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_31_scaled.csv",
        ],
        "D_32_scaled": [
            "d32",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_32_scaled.csv",
        ],
        "D_33_scaled": [
            "d33",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_33_scaled.csv",
        ],
        "alpha_1": [
            "alpha1",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_1.csv",
        ],
        "alpha_2": [
            "alpha2",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_2.csv",
        ],
        "alpha_3": [
            "alpha3",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_3.csv",
        ],
    }

    # for var, datafile in data_dict_three_salt.items():
    #     train_data_set(train_rbf_surrogate_model, datafile, var, True, "surrogate_models/lithium_cobalt_aluminum_chloride/rbf_pysmo_surrogate_d11_scaled", number_of_salts=3)
    #     # train_data_set(train_rbf_surrogate_model, datafile, var, number_of_salts=3)

    key_list = list(data_dict_three_salt.keys())
    # value_list = list(data_dict_three_salt.values())
    # print(key_list[0])
    # print(value_list[0][0])

    for key in key_list:
        # print(key)
        # # print(data_dict_three_salt[key])
        # print(data_dict_three_salt[key][0]) # eg) d11
        # print(data_dict_three_salt[key][-1]) # eg) datafilename

        train_data_set(
            train_rbf_surrogate_model,
            data_dict_three_salt[key][-1],
            key,
            True,
            f"surrogate_models/lithium_cobalt_aluminum_chloride/rbf_pysmo_surrogate_{data_dict_three_salt[key][0]}_scaled",
            number_of_salts=3,
        )
    # train_data_set(
    #     train_rbf_surrogate_model,
    #     data_dict_three_salt[key_list[1]],
    #     key_list[0],
    #     True,
    #     "surrogate_models/lithium_cobalt_aluminum_chloride/rbf_pysmo_surrogate_d12_scaled",
    #     number_of_salts=3,
    # )


def train_data_set(
    surrogate_model_training_function,
    datafilename,
    paramtername,
    save=False,
    savefile=None,
    number_of_salts=None,
):
    if surrogate_model_training_function == train_rbf_surrogate_model:
        trained_model = surrogate_model_training_function(
            datafile=datafilename,
            parametername=paramtername,
            number_of_salts=3,
        )
    else:
        trained_model = surrogate_model_training_function(
            datafile=datafilename,
            parametername=paramtername,
        )
    if save:
        trained_model.save_to_file(
            savefile,
            overwrite=True,
        )


def train_polynomial_surrogate_model(datafile, parametername, max_order=4):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    # create PySMO regression trainer object
    pr_trainer = PysmoPolyTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    # set PySMO options
    pr_trainer.config.maximum_polynomial_order = max_order

    # train surrogate model
    poly_train = pr_trainer.train_surrogate()

    surrogate = PysmoSurrogate(poly_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_kriging_surrogate_model(datafile, parametername):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    krg_trainer = PysmoKrigingTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    krg_trainer.config.numerical_gradients = False

    krg_train = krg_trainer.train_surrogate()

    surrogate = PysmoSurrogate(krg_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_rbf_surrogate_model(datafile, parametername, number_of_salts):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    if number_of_salts == 2:
        input_labels = ["conc_1", "conc_2", "chi"]
        output_labels = [parametername]
        xmin = [50, 50, -150]
        xmax = [200, 200, 0]
        input_bounds = {
            input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
        }
    if number_of_salts == 3:
        input_labels = ["conc_1", "conc_2", "conc_3", "chi"]
        output_labels = [parametername]
        xmin = [50, 50, 50, -150]
        xmax = [200, 200, 200, 0]
        input_bounds = {
            input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
        }

    # n_data = data[input_labels[0]].size
    # data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)
    # print(data_training)

    rbf_trainer = PysmoRBFTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data,  # _training,
    )

    rbf_trainer.config.basis_function = "cubic"

    rbf_train = rbf_trainer.train_surrogate()

    surrogate = PysmoSurrogate(rbf_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data)  # _training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data)  # _validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data, show=True)  # _validation, show=True)
    surrogate_scatter3D(surrogate, data, show=True)  # _validation, show=True)
    surrogate_parity(surrogate, data, show=True)  # _validation, show=True)
    surrogate_residual(surrogate, data, show=True)  # _validation, show=True)

    return surrogate


if __name__ == "__main__":
    main()
