from idaes.core.surrogate.metrics import compute_fit_metrics
from idaes.core.surrogate.pysmo_surrogate import (
    PysmoPolyTrainer,
    PysmoSurrogate,
    PysmoKrigingTrainer,
    PysmoRBFTrainer,
)
from idaes.core.surrogate.sampling.data_utils import split_training_validation
from idaes.core.surrogate.plotting.sm_plotter import (
    surrogate_scatter2D,
    surrogate_scatter3D,
    surrogate_parity,
    surrogate_residual,
)

from pyomo.environ import value

import pandas as pd

# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_polyregression.html
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/index.html#pysmo-python-based-surrogate-modeling-objects
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/plotting/index.html#visualizing-surrogate-model-results
# https://idaes-pse.readthedocs.io/en/stable/explanations/modeling_extensions/surrogate/api/pysmo/pysmo_radialbasisfunctions.html


def main():
    """
    Necessary data is generated by running generate_diffusion_data.py
    """
    # create_and_save_surrogates()
    error_df = two_salt_surrogste_error_analysis()
    print(error_df)


def two_salt_surrogste_error_analysis():
    two_salt_variable_list = [
        "D_11_scaled",
        "D_12_scaled",
        "D_21_scaled",
        "D_22_scaled",
        "alpha_1",
        "alpha_2",
    ]

    # start with test case
    vary_chi = True
    fractional = True
    remove_sum = 1
    extra_center = True

    if vary_chi:
        chi_folder_name = "with_chi_input"
    else:
        chi_folder_name = "without_chi_input"

    if fractional:
        if remove_sum == 1:
            factorial_folder_name = "fractional_factorial_1"
        elif remove_sum == 2:
            factorial_folder_name = "fractional_factorial_2"
    else:
        factorial_folder_name = "full_factorial"

    if extra_center:
        center_folder_name = "with_extra_center"
    else:
        center_folder_name = "without_extra_center"

    rmse_list = []
    mse_list = []
    mae_list = []
    max_ae_list = []
    sse_list = []
    r_sqrd_list = []

    for variable in two_salt_variable_list:
        data_file_name = f"surrogate_data/lithium_cobalt_chloride/{chi_folder_name}/{factorial_folder_name}/{center_folder_name}/{variable}.csv"

        (surrogate, error_metrics) = train_rbf_surrogate_model(
            datafile=data_file_name,
            parametername=variable,
            number_of_salts=2,
            vary_chi=vary_chi,
            basis_func="cubic",
            visualize=False,
        )

        for var, info in error_metrics.items():
            for error_metric, val in info.items():
                if error_metric == "RMSE":
                    rmse_list.append(value(val))
                elif error_metric == "MSE":
                    mse_list.append(value(val))
                elif error_metric == "MAE":
                    mae_list.append(value(val))
                elif error_metric == "maxAE":
                    max_ae_list.append(value(val))
                elif error_metric == "SSE":
                    sse_list.append(value(val))
                elif error_metric == "R2":
                    r_sqrd_list.append(value(val))

    two_salt_variable_list.append("Average")

    rmse_avg = sum(rmse_list) / len(rmse_list)
    mse_avg = sum(mse_list) / len(mse_list)
    mae_avg = sum(mae_list) / len(mae_list)
    max_ae_avg = sum(max_ae_list) / len(max_ae_list)
    sse_avg = sum(sse_list) / len(sse_list)
    r_sqrd_avg = sum(r_sqrd_list) / len(r_sqrd_list)

    rmse_list.append(rmse_avg)
    mse_list.append(mse_avg)
    mae_list.append(mae_avg)
    max_ae_list.append(max_ae_avg)
    sse_list.append(sse_avg)
    r_sqrd_list.append(r_sqrd_avg)

    error_dict = {
        "Variable": two_salt_variable_list,
        "RMSE": rmse_list,
        "MSE": mse_list,
        "MAE": mae_list,
        "maxAE": max_ae_list,
        "SSE": sse_list,
        "R2": r_sqrd_list,
    }

    error_df = pd.DataFrame(error_dict)

    return error_df


def create_and_save_surrogates():
    data_dict_two_salt = {
        "D_11_scaled": [
            "d11_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/D_11_scaled.csv",
        ],
        "D_12_scaled": [
            "d12_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/D_12_scaled.csv",
        ],
        "D_21_scaled": [
            "d21_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/D_21_scaled.csv",
        ],
        "D_22_scaled": [
            "d22_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/D_22_scaled.csv",
        ],
        "alpha_1": [
            "alpha_1",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/alpha_1.csv",
        ],
        "alpha_2": [
            "alpha_2",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_chloride/alpha_2.csv",
        ],
    }

    key_list = list(data_dict_two_salt.keys())

    for key in key_list:
        train_data_set(
            train_rbf_surrogate_model,
            data_dict_two_salt[key][-1],
            key,
            True,
            f"surrogate_models/lithium_cobalt_chloride/fractional_factorial/rbf_pysmo_surrogate_{data_dict_two_salt[key][0]}",
            number_of_salts=2,
        )

    for var, datafile in data_dict_two_salt.items():
        train_data_set(
            train_rbf_surrogate_model,
            datafile,
            var,
            True,
            "surrogate_models/rbf_pysmo_surrogate_d11_scaled",
        )
        # train_data_set(train_kriging_surrogate_model, datafile, var)

    polynomial = False
    if polynomial:
        for var, datafile in data_dict_large_two_salt.items():
            train_data_set(train_polynomial_surrogate_model, datafile, var)

    # data is generated by running generate_diffusion_data.py
    data_dict_three_salt = {
        "D_11_scaled": [
            "d11_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_11_scaled.csv",
        ],
        "D_12_scaled": [
            "d12_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_12_scaled.csv",
        ],
        "D_13_scaled": [
            "d13_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_13_scaled.csv",
        ],
        "D_21_scaled": [
            "d21_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_21_scaled.csv",
        ],
        "D_22_scaled": [
            "d22_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_22_scaled.csv",
        ],
        "D_23_scaled": [
            "d23_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_23_scaled.csv",
        ],
        "D_31_scaled": [
            "d31_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_31_scaled.csv",
        ],
        "D_32_scaled": [
            "d32_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_32_scaled.csv",
        ],
        "D_33_scaled": [
            "d33_scaled",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/D_33_scaled.csv",
        ],
        "alpha_1": [
            "alpha1",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_1.csv",
        ],
        "alpha_2": [
            "alpha2",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_2.csv",
        ],
        "alpha_3": [
            "alpha3",
            "surrogate_data/kriging_or_rbf/lithium_cobalt_aluminum_chloride/alpha_3.csv",
        ],
    }

    key_list = list(data_dict_three_salt.keys())

    for key in key_list:
        train_data_set(
            train_rbf_surrogate_model,
            data_dict_three_salt[key][-1],
            key,
            True,
            f"surrogate_models/lithium_cobalt_aluminum_chloride/rbf_pysmo_surrogate_{data_dict_three_salt[key][0]}",
            number_of_salts=3,
        )


def train_data_set(
    surrogate_model_training_function,
    datafilename,
    paramtername,
    save=False,
    savefile=None,
    number_of_salts=None,
):
    if surrogate_model_training_function == train_rbf_surrogate_model:
        trained_model = surrogate_model_training_function(
            datafile=datafilename,
            parametername=paramtername,
            number_of_salts=number_of_salts,
        )
    else:
        trained_model = surrogate_model_training_function(
            datafile=datafilename,
            parametername=paramtername,
        )
    if save:
        trained_model.save_to_file(
            savefile,
            overwrite=True,
        )


def train_polynomial_surrogate_model(datafile, parametername, max_order=4):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [50, 50, -150]
    xmax = [200, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    # create PySMO regression trainer object
    pr_trainer = PysmoPolyTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    # set PySMO options
    pr_trainer.config.maximum_polynomial_order = max_order

    # train surrogate model
    poly_train = pr_trainer.train_surrogate()

    surrogate = PysmoSurrogate(poly_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_kriging_surrogate_model(datafile, parametername):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    input_labels = ["conc_1", "conc_2", "chi"]
    output_labels = [parametername]
    xmin = [75, 50, -150]
    xmax = [225, 200, 0]
    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    n_data = data[input_labels[0]].size
    data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)

    krg_trainer = PysmoKrigingTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data_training,
    )

    krg_trainer.config.numerical_gradients = False

    krg_train = krg_trainer.train_surrogate()

    surrogate = PysmoSurrogate(krg_train, input_labels, output_labels, input_bounds)

    training_metrics = compute_fit_metrics(surrogate, data_training)
    print("Training Data Set")
    for var, info in training_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    testing_metrics = compute_fit_metrics(surrogate, data_validation)
    print("Testing Data Set")
    for var, info in testing_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    # visualize
    surrogate_scatter2D(surrogate, data_validation, show=True)
    surrogate_scatter3D(surrogate, data_validation, show=True)
    surrogate_parity(surrogate, data_validation, show=True)
    surrogate_residual(surrogate, data_validation, show=True)

    return surrogate


def train_rbf_surrogate_model(
    datafile,
    parametername,
    number_of_salts,
    vary_chi,
    basis_func="cubic",
    visualize=False,
):
    # load data from full expressions
    data = pd.read_csv(datafile)

    # define input and output labels
    if number_of_salts == 2:
        if vary_chi:
            input_labels = ["conc_1", "conc_2", "chi"]
            xmin = [1, 1, -150]
            xmax = [201, 201, 50]
        else:
            input_labels = ["conc_1", "conc_2"]
            xmin = [1, 1]
            xmax = [201, 201]

    elif number_of_salts == 3:
        if vary_chi:
            input_labels = ["conc_1", "conc_2", "conc_3", "chi"]
            xmin = [1, 1, 1, -150]
            xmax = [201, 201, 201, 50]
        else:
            input_labels = ["conc_1", "conc_2", "conc_3"]
            xmin = [1, 1, 1, -150]
            xmax = [201, 201, 201, 50]

    output_labels = [parametername]

    input_bounds = {
        input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))
    }

    rbf_trainer = PysmoRBFTrainer(
        input_labels=input_labels,
        output_labels=output_labels,
        training_dataframe=data,
    )

    rbf_trainer.config.basis_function = basis_func

    rbf_train = rbf_trainer.train_surrogate()

    surrogate = PysmoSurrogate(rbf_train, input_labels, output_labels, input_bounds)

    error_metrics = compute_fit_metrics(surrogate, data)
    for var, info in error_metrics.items():
        for error_metric, val in info.items():
            print(f"{error_metric}={value(val)}")

    if visualize:
        # visualize
        surrogate_scatter2D(surrogate, data, show=True)
        surrogate_scatter3D(surrogate, data, show=True)
        surrogate_parity(surrogate, data, show=True)
        surrogate_residual(surrogate, data, show=True)

    return (surrogate, error_metrics)


if __name__ == "__main__":
    main()
